{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "class POS(enum.Enum):\n",
    "    \"\"\"\n",
    "    This class is an enumerated type containing syntactic attributes of words and phrases and can be\n",
    "    used to build grammars\n",
    "    \n",
    "    Attributes\n",
    "    See individual comments\n",
    "    \n",
    "    Methods\n",
    "    N/A\n",
    "    \"\"\"\n",
    "    \n",
    "    #types\n",
    "    T = 0 #Tense\n",
    "    N = 1 #Noun\n",
    "    V = 2 #Verb\n",
    "    Adj = 3 #Adjective\n",
    "    Adv = 4 #Adverb\n",
    "    P = 5 #Preposition\n",
    "    Det = 6 #Determiner\n",
    "    #levels\n",
    "    Bar = 7 #Bar'\n",
    "    Phrase = 8 #Phrase\n",
    "    #add more specific information\n",
    "    Transitive = 9#Verbs\n",
    "    Intransitive = 10\n",
    "    Ditransitive = 13 #Not sure how to implement this in a binary tree at the moment...\n",
    "    Proper = 11#Nouns\n",
    "    Pro = 12\n",
    "    Mass = 14\n",
    "    Count = 15\n",
    "    Plural = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constituent:\n",
    "    \"\"\"\n",
    "    This class represents a tree of syntactic constituents\n",
    "    \n",
    "    Attributes\n",
    "    word: str\n",
    "        the word contained in this Constituent, if this is a phrasal head / leaf node, None otherwise\n",
    "    \n",
    "    left: Constituent\n",
    "        the left child node, if this is a non-terminal node with two children\n",
    "        or the only child of a node with a single child\n",
    "    \n",
    "    right: Constituent\n",
    "        the right child node, if this is a non-terminal node with two children\n",
    "        or the only child of a node with a single child\n",
    "        \n",
    "    pos: POS tuple\n",
    "        the part of speech of this Constituent\n",
    "        \n",
    "    Methods\n",
    "    formatPos(): str\n",
    "        a helper method that formats the pos attribute for use in __repr__() and __str__()\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, word = None, left = None, right = None, pos = None):\n",
    "        \"\"\"\n",
    "        Constructs all neccesary attributes for the Constituent object\n",
    "        \n",
    "        Parameters\n",
    "        word : str, optional\n",
    "            the word contained in this Constituent, if this is a phrasal head / leaf node, None otherwise\n",
    "\n",
    "        left : Constituent, optional\n",
    "            the left child node, if this is a non-terminal node with two children\n",
    "            or the only child of a node with a single child\n",
    "            \n",
    "        right : Constituent, optional\n",
    "            the right child node, if this is a non-terminal node with two children\n",
    "            or the only child of a node with a single child\n",
    "            \n",
    "        pos : POS tuple\n",
    "            the part of speech of this Constituent\n",
    "        \"\"\"\n",
    "        self.word = word\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        if isinstance(pos, tuple):\n",
    "            self.pos = pos\n",
    "        else:\n",
    "            self.pos = (pos,)\n",
    "            \n",
    "    def __repr__(self):\n",
    "        if self.word != None:\n",
    "            return \"[\" + self.formatPos() + \" \" + self.word + \"]\"\n",
    "        if self.right == self.left:\n",
    "            return \"[\" + self.formatPos() + \" \" + str(self.left) + \"]\"\n",
    "        return \"[\" + self.formatPos() + \" \" + str(self.left) + \" \" + str(self.right) + \"]\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "    \n",
    "    def formatPos(self):\n",
    "        \"\"\"\n",
    "        A helper method that formats the pos attribute for use in __repr__() and __str__()\n",
    "        \n",
    "        Parameters\n",
    "        N/A\n",
    "        \n",
    "        Returns\n",
    "        None\n",
    "        \"\"\"\n",
    "        s = str()\n",
    "        for p in self.pos:\n",
    "            if p == POS.N:\n",
    "                s = s + \"N\"\n",
    "            elif p == POS.V:\n",
    "                s = s + \"V\"\n",
    "            elif p == POS.T:\n",
    "                s = s + \"T\"\n",
    "            elif p == POS.Det:\n",
    "                s = s + \"Det\"\n",
    "            elif p == POS.P:\n",
    "                s = s + \"P\"\n",
    "            elif p == POS.Adj:\n",
    "                s = s + \"Adj\"\n",
    "            elif p == POS.Adv:\n",
    "                s = s + \"Adv\"\n",
    "            if p == POS.Phrase:\n",
    "                s = s + \"P\"\n",
    "            elif p == POS.Bar:\n",
    "                s = s + \"'\"\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class Grammar:\n",
    "    \"\"\"\n",
    "    A class representing a grammar in memory, including the lexicon, unary production rules, and binary production rules\n",
    "    \n",
    "    Attributes\n",
    "    uniGrammar: dict\n",
    "        a dictionary using POS objects to represent unary production rules\n",
    "    binGrammar: dict\n",
    "        a dictionary using POS objects to represent binary production rules\n",
    "    lexicon: dict\n",
    "        a dictionary using POS objects and strings to represent word categories\n",
    "        \n",
    "    Methods\n",
    "    add(i, o): \n",
    "        simplified way to enter grammar rules, sorts grammar rules by content to use addBin(), addUni(), or addLexicon()\n",
    "    addBin(constituents, phrase):\n",
    "        adds a binary production rule to self.binGrammar in which the constituents join together to form a phrase\n",
    "    addUni(constituent, phrase):\n",
    "        adds a unary production rule to self.uniGrammar in which the constituent is also a phrase\n",
    "    addLexicon(word, pos):\n",
    "        adds an entry to the lexicon in which the word is an instance of a pos\n",
    "    parseWord(word): Constituent list\n",
    "        returns the list of all Constituents that can be formed containing this word, according to lexicon\n",
    "    parseConstituents(lefts, rights): Constituent list\n",
    "        returns the list of all Constituents that can be formed using any pairing of a Constituent in lefts \n",
    "            and a Constituent in rights, according to binGrammar or uniGrammar\n",
    "    parse(phrase): Constituent set\n",
    "        returns the set of all Constituents that span the entire phrase\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructs all neccesary attributes for the Grammar object\n",
    "        \n",
    "        Parameters\n",
    "        N/A\n",
    "        \"\"\"\n",
    "        self.uniGrammar = {}\n",
    "        self.binGrammar = {}\n",
    "        self.lexicon = {}\n",
    "       \n",
    "    def add(self, i, o):\n",
    "        \"\"\"\n",
    "        Simplified way to enter grammar rules, sorts grammar rules by content to use addBin(), addUni(), or addLexicon()\n",
    "        \n",
    "        Parameters\n",
    "        i : str, POS tuple, or POS tuple tuple\n",
    "            the \"in\" of the production rule - the constituent, constituent(s) or word that are subsumed into the Constituent\n",
    "        o : POS tuple\n",
    "            the \"out\" of the production rule - the type of Constituent that is formed\n",
    "            \n",
    "        Returns\n",
    "        None\n",
    "        \"\"\"\n",
    "        if isinstance(i, str):\n",
    "            if not isinstance(o, set):\n",
    "                o = [o]\n",
    "            self.addLexicon(i, o)\n",
    "        elif isinstance(i, tuple):\n",
    "            if [type(e) for e in i] == [tuple, tuple]:\n",
    "                self.addBin(i, o)\n",
    "            else:\n",
    "                self.addUni(i, o)\n",
    "                \n",
    "    def addBin(self, constituents, phrase):\n",
    "        \"\"\"\n",
    "        Adds a binary production rule to self.binGrammar in which the constituents join together to form a phrase\n",
    "        \n",
    "        Parameters\n",
    "        constituents : POS tuple tuple\n",
    "            the pair of Constituents (POS tuples) that can be joined into one phrase\n",
    "        phrase : POS tuple\n",
    "            the pos of the new Constituent that is formed\n",
    "                \n",
    "        Returns\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.binGrammar[constituents] = phrase\n",
    "        \n",
    "    def addUni(self, constituent, phrase):\n",
    "        \"\"\"\n",
    "        Adds a unary production rule to self.uniGrammar in which the constituent forms a phrase\n",
    "        \n",
    "        Parameters\n",
    "        constituent : POS tuple\n",
    "            the type of Constituent that forms a phrase\n",
    "        phrase : POS tuple\n",
    "            the type of phrase that that Constituent can form\n",
    "                \n",
    "        Returns\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.uniGrammar[constituent] = phrase\n",
    "        \n",
    "    def addLexicon(self, word, pos):\n",
    "        \"\"\"\n",
    "        Adds an entry to the lexicon in which the word is an instance of a pos\n",
    "        \n",
    "        Parameters\n",
    "        word : str\n",
    "            the word that is defined as an instance of a particular part of speech\n",
    "        pos : POS tuple\n",
    "            the definition of the part of speech that the word is classified as\n",
    "            \n",
    "        Returns\n",
    "        None\n",
    "        \"\"\"\n",
    "        if word.lower() not in self.lexicon:\n",
    "            self.lexicon[word.lower()] = set()\n",
    "        for p in pos:\n",
    "            self.lexicon[word.lower()].add(p)\n",
    "    \n",
    "    def parseWord(self, word):\n",
    "        \"\"\"\n",
    "        The list of all Constituents that can be formed containing this word, according to lexicon\n",
    "\n",
    "        Parameters\n",
    "        word : str\n",
    "            the word to be parsed into a leaf Constituent\n",
    "        \n",
    "        Returns\n",
    "        parses (Constituent list):\n",
    "            the list of all possible Constituents that can be formed containing only this word, according to self.lexicon\n",
    "        \"\"\"\n",
    "        parses = []\n",
    "        typeList = None\n",
    "        if word.lower() in self.lexicon:\n",
    "            typeList = self.lexicon[word.lower()]\n",
    "        if typeList != None:\n",
    "            for c in typeList:\n",
    "                parses.append(Constituent(pos = c, word = word));\n",
    "        return parses\n",
    "    \n",
    "    def parseConstituents(self, lefts, rights):\n",
    "        \"\"\"\n",
    "        Returns the list of all Constituents that can be formed using any pairing of a Constituent in lefts \n",
    "            and a Constituent in rights, according to binGrammar or uniGrammar\n",
    "\n",
    "        Parameters\n",
    "        lefts : Constituent list\n",
    "            a list of all Constituents that could become the left child of this Constituent, if the grammar allows\n",
    "        rights : Constituent list\n",
    "            a list of all Constituents that could become the right child of this Consituent, if the grammar allows\n",
    "            \n",
    "        Returns\n",
    "            parses (Constituent list):\n",
    "                the list of all possible Constituents that can be formed using one of the Constituents contained in lefts\n",
    "                    as a left child and one of the constituents in rights as the right child\n",
    "        \"\"\"\n",
    "        parses = []\n",
    "        if lefts == rights:\n",
    "            for left in lefts:\n",
    "                c = None\n",
    "                if left.pos in self.uniGrammar:\n",
    "                    c = self.uniGrammar[left.pos]\n",
    "                if c != None:\n",
    "                    \n",
    "                    constituent = Constituent(pos = c, left = left, right = left)\n",
    "                    parses.append(constituent)\n",
    "        else:\n",
    "            for left in lefts:\n",
    "                for right in rights:\n",
    "                    c = None\n",
    "                    if (left.pos, right.pos) in self.binGrammar:\n",
    "                        c = self.binGrammar[(left.pos, right.pos)]\n",
    "                    if c != None:\n",
    "                        constituent = Constituent(pos = c, left = left, right = right)\n",
    "                        parses.append(constituent)\n",
    "        return parses\n",
    "       \n",
    "    def parse(self, phrase):\n",
    "        \"\"\"\n",
    "        Parses a phrase into a full tree of syntactic Constituents\n",
    "        \n",
    "        Parameters\n",
    "        phrase: str\n",
    "            the phrase to parse\n",
    "        \n",
    "        Returns\n",
    "        parses:\n",
    "            the set of all parses spanning the entire input phrase\n",
    "        \"\"\"\n",
    "        words = re.sub(r'[-;,:\\\"\\'\\\\)(%$!.?~@^*]', \"\", phrase).split()\n",
    "    \n",
    "        matrix = [[set() for x in range(len(words))] for y in range(len(words))]\n",
    "    \n",
    "        for i in range(len(words)):\n",
    "            y = 0\n",
    "            x = i\n",
    "            for j in range(i, len(words)):\n",
    "                if x == y:\n",
    "                    word = words[x]\n",
    "                    for c in self.parseWord(word):\n",
    "                        matrix[y][x].add(c)\n",
    "                totalOffset = x - y\n",
    "                for offset in range(totalOffset):\n",
    "                    for c in self.parseConstituents(matrix[y][x-totalOffset+offset], matrix[y+offset+1][x]):\n",
    "                        matrix[y][x].add(c)\n",
    "                #account for unary production rules\n",
    "                parseCount = 0#there were 0 or more possible parses\n",
    "                while len(matrix[y][x]) != parseCount:\n",
    "                    for c in self.parseConstituents(matrix[y][x], matrix[y][x]):\n",
    "                        matrix[y][x].add(c)\n",
    "                    parseCount = len(matrix[y][x])\n",
    "                #increment\n",
    "                x += 1\n",
    "                y += 1\n",
    "        return matrix[0][len(words)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grammars:\n",
    "    \"\"\"\n",
    "    This class contains several example Grammars for demonstration purposes, although users can construct custom Grammars \n",
    "    \n",
    "    Attributes\n",
    "    N/A\n",
    "    \n",
    "    Methods\n",
    "    simple(): Grammar\n",
    "        returns a simple Grammar object with three vocabulary words and two production rules\n",
    "        \n",
    "    demo(): Grammar\n",
    "        returns a grammar that only supports pronouns or Determiners + Nouns as noun phrases, and only supports transitive verbs\n",
    "        used for demonstrating these classes\n",
    "        \n",
    "    complex(): Grammar\n",
    "        returns an overly complex grammar that should very detailedly reflect english syntax, but has errors\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def simple():\n",
    "        \"\"\"\n",
    "        returns a simple Grammar object with three vocabulary words and two production rules\n",
    "        \"\"\"\n",
    "        g = Grammar()\n",
    "        g.add(\"this\", (POS.N, POS.Phrase))\n",
    "        g.add(\"is\", (POS.V,))\n",
    "        g.add(\"syntax\", (POS.N, POS.Phrase))\n",
    "        g.add(((POS.V,), (POS.N, POS.Phrase)), (POS.V, POS.Phrase))\n",
    "        g.add(((POS.N, POS.Phrase), (POS.V, POS.Phrase)), (POS.T, POS.Phrase))\n",
    "        return g\n",
    "        \n",
    "    @staticmethod\n",
    "    def demo():\n",
    "        \"\"\"\n",
    "        returns a grammar that only supports pronouns or Determiners + Nouns as noun phrases, and only supports transitive verbs\n",
    "        used for demonstrating these classes\n",
    "        \"\"\"\n",
    "        g = Grammar()\n",
    "        #Pronouns\n",
    "        g.add(\"I\", (POS.N, POS.Pro))\n",
    "        g.add(\"me\", (POS.N, POS.Pro))\n",
    "        g.add(\"we\", (POS.N, POS.Pro))\n",
    "        g.add(\"us\", (POS.N, POS.Pro))\n",
    "        g.add(\"you\", (POS.N, POS.Pro))\n",
    "        g.add(\"he\", (POS.N, POS.Pro))\n",
    "        g.add(\"him\", (POS.N, POS.Pro))\n",
    "        g.add(\"she\", (POS.N, POS.Pro))\n",
    "        g.add(\"her\", (POS.N, POS.Pro))\n",
    "        g.add(\"they\", (POS.N, POS.Pro))\n",
    "        g.add(\"them\", (POS.N, POS.Pro))\n",
    "        g.add((POS.N, POS.Pro), (POS.N, POS.Phrase))\n",
    "        \n",
    "        #Nouns\n",
    "        g.add(\"man\", (POS.N,))\n",
    "        g.add(\"binoculars\", (POS.N,))\n",
    "        g.add(\"dog\", (POS.N,))\n",
    "        g.add(\"park\", (POS.N,))\n",
    "        g.add(((POS.Det,), (POS.N,)), (POS.N, POS.Phrase))#NP -> Det N\n",
    "        g.add(((POS.N, POS.Phrase), (POS.P, POS.Phrase)), (POS.N, POS.Phrase))#NP -> NP PP\n",
    "        \n",
    "        #Determiners\n",
    "        g.add(\"the\", (POS.Det,))\n",
    "        g.add(\"a\", (POS.Det,))\n",
    "        g.add(\"an\", (POS.Det,))\n",
    "        g.add(\"my\", (POS.Det,))\n",
    "        \n",
    "        #Verbs\n",
    "        g.add(\"saw\", (POS.V,))\n",
    "        g.add(\"see\", (POS.V,))\n",
    "        g.add(\"have\", (POS.V,))\n",
    "        g.add(\"found\", (POS.V,))\n",
    "        g.add(((POS.V,), (POS.N, POS.Phrase)), (POS.V, POS.Phrase))#VP -> V NP\n",
    "        g.add(((POS.V, POS.Phrase), (POS.P, POS.Phrase)), (POS.V, POS.Phrase))#VP -> VP PP\n",
    "        \n",
    "        #Prepositions\n",
    "        g.add(\"with\", (POS.P,))\n",
    "        g.add(\"in\", (POS.P,))\n",
    "        g.add(((POS.P,), (POS.N, POS.Phrase)), (POS.P, POS.Phrase))#PP -> P NP\n",
    "        \n",
    "        g.add(((POS.N, POS.Phrase), (POS.V, POS.Phrase)), (POS.T, POS.Phrase))\n",
    "        \n",
    "        return g\n",
    "        \n",
    "    @staticmethod\n",
    "    def complex():#This one is kinda broken cause I tried to make it too complex. \n",
    "        \"\"\"\n",
    "        returns an overly complex grammar that should very detailedly reflect english syntax, but has errors\n",
    "        \"\"\"\n",
    "        g = Grammar()\n",
    "        #lexicon\n",
    "        g.add(\"I\", (POS.N, POS.Pro))#Pronouns\n",
    "        g.add(\"me\", (POS.N, POS.Pro))\n",
    "        g.add(\"we\", (POS.N, POS.Pro))\n",
    "        g.add(\"us\", (POS.N, POS.Pro))\n",
    "        g.add(\"you\", (POS.N, POS.Pro))\n",
    "        g.add(\"he\", (POS.N, POS.Pro))\n",
    "        g.add(\"him\", (POS.N, POS.Pro))\n",
    "        g.add(\"she\", (POS.N, POS.Pro))\n",
    "        g.add(\"her\", (POS.N, POS.Pro))\n",
    "        g.add(\"they\", (POS.N, POS.Pro))\n",
    "        g.add(\"them\", (POS.N, POS.Pro))\n",
    "        g.add(\"saw\", (POS.N, POS.Count))#Count Nouns\n",
    "        g.add(\"dog\", (POS.N, POS.Count))\n",
    "        g.add(\"sky\", (POS.N, POS.Count))\n",
    "        g.add(\"car\", (POS.N, POS.Count))\n",
    "        g.add(\"cat\", (POS.N, POS.Count))\n",
    "        g.add(\"person\", (POS.N, POS.Count))\n",
    "        g.add(\"saws\", (POS.N, POS.Plural))#Plural Nouns\n",
    "        g.add(\"dogs\", (POS.N, POS.Plural))\n",
    "        g.add(\"cars\", (POS.N, POS.Plural))\n",
    "        g.add(\"cats\", (POS.N, POS.Plural))\n",
    "        g.add(\"people\", (POS.N, POS.Plural))\n",
    "        g.add(\"water\", (POS.N, POS.Mass))#Mass Nouns\n",
    "        g.add(\"go\", (POS.V, POS.Intransitive))#Intransitive Verbs\n",
    "        g.add(\"saw\", (POS.V, POS.Transitive))#Transitive Verbs\n",
    "        g.add(\"have\", (POS.V, POS.Transitive))\n",
    "        g.add(\"to\", (POS.P,))#Pronouns\n",
    "        g.add(\"through\", (POS.P,))\n",
    "        g.add(\"from\", (POS.P,))\n",
    "        g.add(\"with\", (POS.P,))\n",
    "        g.add(\"the\", (POS.Det,))#Determiners\n",
    "        g.add(\"an\", (POS.Det,))\n",
    "        g.add(\"a\", (POS.Det,))\n",
    "        #syntax - unary\n",
    "        g.add((POS.N, POS.Pro), (POS.Det, POS.Phrase))#DetP -> NPro #Nouns \n",
    "        g.add((POS.N, POS.Pro), (POS.N, POS.Phrase))#NP -> NPro\n",
    "        g.add((POS.N, POS.Proper), (POS.Det, POS.Phrase))#DetP -> NPro\n",
    "        g.add((POS.N, POS.Proper), (POS.N, POS.Phrase))#NP -> NProper\n",
    "        g.add((POS.N, POS.Mass), (POS.N, POS.Bar))#N' -> NMass\n",
    "        g.add((POS.N, POS.Plural), (POS.N, POS.Bar))#N' -> NPlural\n",
    "        g.add((POS.N, POS.Phrase), (POS.Det, POS.Phrase))#DP -> NP\n",
    "        g.add((POS.N, POS.Count), (POS.N, POS.Count, POS.Bar))\n",
    "        g.add((POS.N, POS.Bar), (POS.N, POS.Phrase))\n",
    "        g.add((POS.V, POS.Intransitive), (POS.V, POS.Bar))#Verbs\n",
    "        g.add((POS.V, POS.Bar), (POS.V, POS.Phrase))\n",
    "        g.add((POS.Adj,), (POS.Adj, POS.Bar))#Adjectives\n",
    "        g.add((POS.Adj, POS.Bar), (POS.Adj, POS.Phrase))\n",
    "        g.add((POS.Adv,), (POS.Adv, POS.Bar))#Adverb\n",
    "        g.add((POS.Adv, POS.Bar), (POS.Adv, POS.Phrase))\n",
    "        g.add((POS.Det, POS.Bar), (POS.Det, POS.Phrase))#Determiners\n",
    "        g.add((POS.P, POS.Bar), (POS.P, POS.Phrase))#Prepositions\n",
    "        #syntax - binary\n",
    "        g.add(((POS.Det, POS.Phrase), (POS.V, POS.Phrase)), (POS.T, POS.Phrase))#Sentence\n",
    "        g.add(((POS.Adv, POS.Phrase), (POS.Adj)), (POS.Adj, POS.Bar))#AdvP + Adj -> Adj' \n",
    "        g.add(((POS.Adv, POS.Phrase), (POS.Adv)), (POS.Adv, POS.Bar))#AdvP + Adv -> Adv' \n",
    "        g.add(((POS.Adj, POS.Phrase), (POS.N, POS.Count, POS.Bar)), (POS.N, POS.Count, POS.Bar)) #Nouns\n",
    "        g.add(((POS.N, POS.Count, POS.Bar), (POS.P, POS.Phrase)), (POS.N, POS.Count, POS.Bar))\n",
    "        g.add(((POS.Adj, POS.Phrase), (POS.N, POS.Bar)), (POS.N, POS.Bar))\n",
    "        g.add(((POS.N, POS.Bar), (POS.P, POS.Phrase)), (POS.N, POS.Bar))\n",
    "        g.add(((POS.V, POS.Transitive), (POS.Det, POS.Phrase)), (POS.V, POS.Bar))#Verbs\n",
    "        g.add(((POS.V, POS.Bar), (POS.Adv, POS.Phrase)), (POS.V, POS.Bar))\n",
    "        g.add(((POS.V, POS.Bar), (POS.P, POS.Phrase)), (POS.V, POS.Bar))\n",
    "        g.add(((POS.Det,), (POS.N, POS.Phrase)), (POS.Det, POS.Bar))#Determiners\n",
    "        g.add(((POS.P,), (POS.Det, POS.Phrase)), (POS.P, POS.Bar))#Prepositions\n",
    "        return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{[TP [NP This] [VP [V is] [NP syntax]]]}\n"
     ]
    }
   ],
   "source": [
    "#This is my CYK parser. Let's parse a simple sentence with my simple grammar:\n",
    "print(Grammars.simple().parse(\"This is syntax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{[TP [NP [N I]] [VP [VP [V saw] [NP [Det the] [N man]]] [PP [P with] [NP [Det the] [N binoculars]]]]], [TP [NP [N I]] [VP [V saw] [NP [NP [Det the] [N man]] [PP [P with] [NP [Det the] [N binoculars]]]]]]}\n"
     ]
    }
   ],
   "source": [
    "#My parser can handle ambiguity! If there are multiple grammatical parses, it returns both in a python set:\n",
    "print(Grammars.demo().parse(\"I saw the man with the binoculars\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{[TP [NP [N I]] [VP [V found] [NP [NP [Det my] [N dog]] [PP [P in] [NP [Det the] [N park]]]]]], [TP [NP [N I]] [VP [VP [V found] [NP [Det my] [N dog]]] [PP [P in] [NP [Det the] [N park]]]]]}\n"
     ]
    }
   ],
   "source": [
    "#(It doesn't have any knowledge of Semantics though, so sometimes it thinks non-ambiguous sentences are actually ambiguous):\n",
    "print(Grammars.demo().parse(\"I found my dog in the park\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "#If it encounters any words it does not know, OR if it knows the words, but they don't\n",
    "# make sense syntactically, it returns an empty set:\n",
    "print(Grammars.simple().parse(\"This is phonology\"))\n",
    "print(Grammars.simple().parse(\"Syntax this is\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{[TP [NP [N I]] [VP [V sAw] [NP [Det tHE] [N binoCUlaRs]]]]}\n"
     ]
    }
   ],
   "source": [
    "#It uses regular expressions to ignore punctuation and capitalization (but keeps the \n",
    "# original capitalization in the final bracket notation):\n",
    "print(Grammars.demo().parse(\"~~~I sA@w;; tH.E b!inoCU::laRs~~~\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{[PP [P with] [NP [Det my] [N dog]]]}\n"
     ]
    }
   ],
   "source": [
    "#I didn't limit my parser to only display full parses that resolve to a complete sentence:\n",
    "print(Grammars.demo().parse(\"with my dog\"))\n",
    "#Instead it displays any parses that span the whole input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{[TP [NP Ich] [VP [VP [V verstehe] [NP Deutsch]] [AdvP [Adv auch]]]]}\n"
     ]
    }
   ],
   "source": [
    "#In addition to using the simple pre-made grammars that I built (in the Grammars class), you can also make custom ones!\n",
    "deutscheGrammatik = Grammar()\n",
    "deutscheGrammatik.add(\"Ich\", (POS.N, POS.Phrase)) # NP -> \"Ich\"\n",
    "deutscheGrammatik.add(\"verstehe\", (POS.V,)) # V -> \"verstehe\"\n",
    "deutscheGrammatik.add(\"Deutsch\", (POS.N, POS.Phrase)) #NP -> \"Deutsch\"\n",
    "deutscheGrammatik.add(\"auch\", (POS.Adv,))\n",
    "deutscheGrammatik.add((POS.Adv,), (POS.Adv, POS.Phrase))\n",
    "deutscheGrammatik.add(((POS.V,), (POS.N, POS.Phrase)), (POS.V, POS.Phrase)) # VP -> V NP\n",
    "deutscheGrammatik.add(((POS.V, POS.Phrase), (POS.Adv, POS.Phrase)), (POS.V, POS.Phrase)) # VP -> VP AdvP\n",
    "deutscheGrammatik.add(((POS.N, POS.Phrase), (POS.V, POS.Phrase)), (POS.T, POS.Phrase)) # TP -> NP VP\n",
    "print(deutscheGrammatik.parse(\"Ich verstehe Deutsch auch!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{[N this]}\n",
      "{[Det this], [N this]}\n",
      "{[Det this], [N this], [NP [N this]]}\n",
      "{[TP [NP [N This]] [VP [V works]]]}\n",
      "{[NP [Det This] [N work]]}\n"
     ]
    }
   ],
   "source": [
    "#There are three formats to keep in mind when adding rules to a custom grammar:\n",
    "customGrammar = Grammar()\n",
    "\n",
    "#vocabulary - use the word as your first parameters, and the Part of Speech (as a tuple) as the second:\n",
    "customGrammar.add(   \"this\",   (POS.N, POS.Pro)   ) #\"this\" is a pronoun\n",
    "print(customGrammar.parse(\"this\"))\n",
    "#you can use multiple parses for the same vocabulary word:\n",
    "customGrammar.add(   \"this\",     (POS.Det,)   ) #\"this\" is a determiner\n",
    "print(customGrammar.parse(\"this\"))\n",
    "\n",
    "#unary production rules - use a Part of Speech (as a tuple) for both parameters:\n",
    "customGrammar.add(   (POS.N, POS.Pro),   (POS.N, POS.Phrase)   ) #NP -> Pronoun\n",
    "print(customGrammar.parse(\"this\"))\n",
    "\n",
    "#binary production rules - use a tuple of Parts of Speech (both as tuples themselves) for the first parameter, and \n",
    "# another Part of Speech (still a tuple) as the second:\n",
    "customGrammar.add(   (  (POS.Det,),  (POS.N,)  ),   (POS.N, POS.Phrase)   ) #NP -> Det N\n",
    "customGrammar.add(   (  (POS.N, POS.Phrase),  (POS.V, POS.Phrase)  ),   (POS.T, POS.Phrase)   ) #TP -> NP VP\n",
    "#adding more grammar/vocabulary to build phrases out of:\n",
    "customGrammar.add(   \"works\",     (POS.V,)   ) #\"works\" is a Verb\n",
    "customGrammar.add(   (POS.V,),   (POS.V, POS.Phrase)   ) #VP -> V\n",
    "customGrammar.add(   \"work\",     (POS.N,)   ) #\"works\" is a Verb\n",
    "print(customGrammar.parse(\"This works!\"))\n",
    "print(customGrammar.parse(\"This work\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
